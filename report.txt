# Chess assignment report

(Replace the square-bracketed text with your own text. *Leave everything else unchanged.* Note, the reports are parsed to check word limits, etc. Changing the format may cause the parsing to fail.)

## Feature Extraction (Max 200 Words)

I have used Principal Component Analysis (PCA) to reduce the dimension. A 
covariance matrix of the dataset is calculated, in which 10 principle 10 biggest 
eigenvalues is obtained, which will represent the original data the most 
accurately after performing matrix multiplication on the original data.

## Classifier (Max 200 Words)

During the training stage, the dataset is split into different classes, a class 
mean and variance is calculated for each of the datasets, this is stored in the 
model which is each then used in the classification stage to generate a Gaussian 
distribution model for each of the classes.

The Gaussian distribtions are then used to classify the individual squares
during the testing stage, using Bayes' decision method to assign a sample to 
the class with the biggest probability given.

I initially used the Gaussian approach because I was most familiar with this 
method, but now that I think about it, a k-nearest neighbour might have been a 
better approach at classifying the individual squares, since a piece can be on 
both black and white squares, but during the training stage this was not put 
into consideration. And if we were to further split the dataset by the class 
AND the color of a square, we would end up with twice the number of Gaussian 
distribution models with less training data used for each, resulting in less 
accuracy.

## Full Board Classification (Max 200 Words)

An idea that I came up was
    - construct a list of lists of size 64, each list stores every label (include duplicates) thats occurred in a particular position
    - multiply probability of occurence of each class + 1, by the probability of a square belonging to a Gaussian distribution of the corresponding class 
    - (add 1 so we don't totally eliminate an probability by multiplying by 0, if there were no occurence of a piece on a particular position)
    - classify squares according to modified probabilities

After implmenting this idea, I was able to increase the accuracy for the clean data by 0.3%.

## Performance

My percentage correctness scores (to 1 decimal place) for the development data are as follows.

Clean data:

- Square mode: 97.4%
- Board mode: 97.4%

Noisy data:

- Square mode: 93.6%
- Board mode: 93.6%

## Other information (Optional, Max 100 words)

